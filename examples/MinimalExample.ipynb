{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_regression, make_low_rank_matrix\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from gprEmbedding import SubspaceKernel, EmbeddingRBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'code_example_data'\n",
    "trainX = pd.read_csv(join(path, 'trainX.csv'), index_col=0)\n",
    "trainY = pd.read_csv(join(path, 'trainY.csv'), index_col=0)\n",
    "    \n",
    "testX = pd.read_csv(join(path, 'testX.csv'), index_col=0)\n",
    "testY = pd.read_csv(join(path, 'testY.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VCD</th>\n",
       "      <th>Glc</th>\n",
       "      <th>Gln</th>\n",
       "      <th>Amm</th>\n",
       "      <th>Lac</th>\n",
       "      <th>product</th>\n",
       "      <th>reactor_temperature</th>\n",
       "      <th>pH</th>\n",
       "      <th>reactor_volume</th>\n",
       "      <th>stirring_rate</th>\n",
       "      <th>inital_volume</th>\n",
       "      <th>total_run_time</th>\n",
       "      <th>product_is_clever_lemon</th>\n",
       "      <th>product_is_relaxed_soup</th>\n",
       "      <th>product_is_novel_brick</th>\n",
       "      <th>product_is_savage_yogurt</th>\n",
       "      <th>product_is_forgiving_crumble</th>\n",
       "      <th>product_is_NNcurious_pretzel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.497567</td>\n",
       "      <td>47.187399</td>\n",
       "      <td>8.418417</td>\n",
       "      <td>21.040312</td>\n",
       "      <td>19.233585</td>\n",
       "      <td>554.786905</td>\n",
       "      <td>36.603477</td>\n",
       "      <td>6.848805</td>\n",
       "      <td>0.240</td>\n",
       "      <td>168.361456</td>\n",
       "      <td>0.25</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.149359</td>\n",
       "      <td>15.519523</td>\n",
       "      <td>9.419511</td>\n",
       "      <td>9.228290</td>\n",
       "      <td>69.201177</td>\n",
       "      <td>593.394556</td>\n",
       "      <td>36.838207</td>\n",
       "      <td>6.973305</td>\n",
       "      <td>0.250</td>\n",
       "      <td>170.309117</td>\n",
       "      <td>0.25</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.645692</td>\n",
       "      <td>15.497978</td>\n",
       "      <td>0.637340</td>\n",
       "      <td>5.118473</td>\n",
       "      <td>70.339972</td>\n",
       "      <td>747.287453</td>\n",
       "      <td>36.962887</td>\n",
       "      <td>6.705709</td>\n",
       "      <td>0.235</td>\n",
       "      <td>164.639278</td>\n",
       "      <td>0.25</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.355481</td>\n",
       "      <td>42.822897</td>\n",
       "      <td>5.192189</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.034637</td>\n",
       "      <td>6.950299</td>\n",
       "      <td>0.250</td>\n",
       "      <td>191.907496</td>\n",
       "      <td>0.25</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.215053</td>\n",
       "      <td>53.815468</td>\n",
       "      <td>8.999396</td>\n",
       "      <td>4.476596</td>\n",
       "      <td>13.620892</td>\n",
       "      <td>22.769994</td>\n",
       "      <td>36.878436</td>\n",
       "      <td>6.981446</td>\n",
       "      <td>0.250</td>\n",
       "      <td>182.791211</td>\n",
       "      <td>0.25</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VCD        Glc       Gln        Amm        Lac     product  \\\n",
       "0  0.497567  47.187399  8.418417  21.040312  19.233585  554.786905   \n",
       "1  2.149359  15.519523  9.419511   9.228290  69.201177  593.394556   \n",
       "2  1.645692  15.497978  0.637340   5.118473  70.339972  747.287453   \n",
       "3  0.355481  42.822897  5.192189   0.100000   0.100000    0.000000   \n",
       "4  1.215053  53.815468  8.999396   4.476596  13.620892   22.769994   \n",
       "\n",
       "   reactor_temperature        pH  reactor_volume  stirring_rate  \\\n",
       "0            36.603477  6.848805           0.240     168.361456   \n",
       "1            36.838207  6.973305           0.250     170.309117   \n",
       "2            36.962887  6.705709           0.235     164.639278   \n",
       "3            37.034637  6.950299           0.250     191.907496   \n",
       "4            36.878436  6.981446           0.250     182.791211   \n",
       "\n",
       "   inital_volume  total_run_time  product_is_clever_lemon  \\\n",
       "0           0.25           336.0                      0.0   \n",
       "1           0.25           336.0                      0.0   \n",
       "2           0.25           336.0                      0.0   \n",
       "3           0.25           336.0                      0.0   \n",
       "4           0.25           336.0                      0.0   \n",
       "\n",
       "   product_is_relaxed_soup  product_is_novel_brick  product_is_savage_yogurt  \\\n",
       "0                      1.0                     0.0                       0.0   \n",
       "1                      0.0                     0.0                       0.0   \n",
       "2                      0.0                     1.0                       0.0   \n",
       "3                      0.0                     0.0                       0.0   \n",
       "4                      0.0                     0.0                       1.0   \n",
       "\n",
       "   product_is_forgiving_crumble  product_is_NNcurious_pretzel  \n",
       "0                           0.0                           0.0  \n",
       "1                           1.0                           0.0  \n",
       "2                           0.0                           0.0  \n",
       "3                           1.0                           0.0  \n",
       "4                           0.0                           0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Data\n",
    "The example data set is concerned with cell processes in biology. For different cell lines (or products) we predict the growth rate of the cells. \n",
    "\n",
    "The target `y` is the current rate of cell growth.  \n",
    "The features `X` contain real valued information like Temperature, pH or current concentrations of nutrients in the brooth. Additionally,\n",
    "the identity of the product is represented with a one-hot vector in the last 6 columns. \n",
    "\n",
    "# The Method\n",
    "We implemented a custom kernel `EmbeddingRBF` that will essentially replace the one-hot vectors in the raw data with a learned embedding vector. It implements the kernel function\n",
    "\n",
    "$$k(x, y) =  exp(- ||Wx- Wy||^2 ) $$\n",
    "\n",
    "where W is a learned matrix. `x` and `y` are one-hot vectors. This kernel is applied to the one-hot vector that encodes the product identity and multiplied with an RBF kernel which is applied to the remaining features. This is equivalent to replacing the one-hot vectors with the learned embeddings (correct columns in W) and then feeding them together with the normal features into a normal RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 12 # the number of normal features\n",
    "n_products = 6 # the number of products \n",
    "embedding_dimension = 2 # can be choosen freely\n",
    "\n",
    "prod_col_names = trainX.columns.values[-n_products:].tolist() # the names of the columns encoding the product identity\n",
    "prod_col_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(hat, target):\n",
    "    target = target.values\n",
    "    sq = (hat-target)**2\n",
    "    return np.sqrt(np.mean(sq))/np.std(target)\n",
    "\n",
    "def MDe(hat, target):\n",
    "    target = target.values\n",
    "    sq = (hat-target)**2\n",
    "    return np.sqrt(np.median(sq))/np.std(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply RBF kernel to the normal features\n",
    "raw_normal_feature_kernel = RBF(length_scale = [1.0]*n_features)\n",
    "# The SubspaceKernel ensures that the RBF kernel is only applied to the first 10 features\n",
    "normal_feature_kernel = SubspaceKernel(raw_normal_feature_kernel, ids_to_apply=np.arange(0, n_features))\n",
    "\n",
    "# Apply Embedding kernel to the last 6 features, that contain a one-hot representation of the product\n",
    "raw_embedding_kernel = EmbeddingRBF.make4EntityEmbed(n_entities=n_products, embedding_dimension=embedding_dimension)\n",
    "# Use SubspaceKernel to indicate that the one-hot feature representation is contained in the last 6 columns\n",
    "embedding_kernel = SubspaceKernel(raw_embedding_kernel, ids_to_apply=np.arange(n_features, n_features+n_products))\n",
    "\n",
    "# Combine the kernel and allow for Noise\n",
    "full_kernel = 1**2*normal_feature_kernel*embedding_kernel + WhiteKernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_gp = GaussianProcessRegressor(kernel=full_kernel, n_restarts_optimizer=1, normalize_y=True)\n",
    "\n",
    "embedding_gp.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_embed = embedding_gp.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('standardised root mean square error: {:.4f}'.format(rmse(hat=y_hat_embed, target=testY)))\n",
    "print('standardised median error: {:.4f}'.format(MDe(hat=y_hat_embed, target=testY)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovering the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
